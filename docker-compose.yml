version: "3"

services:
  bench_transformers:
    image: bench_transformers_img
    build:
      context: .
      dockerfile: Dockerfile-tf
    runtime: nvidia
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    volumes:
      - ./llm_benchmarks:/app/llm_benchmarks
      - ./logs/:/var/log
      - /rocket/hf:/rocket/hf
    network_mode: host
    environment:
      - CUDA_VISIBLE_DEVICES=0
  bench_cpp:
    image: bench_cpp_img
    build:
      context: https://github.com/abetlen/llama-cpp-python.git
      dockerfile: docker/cuda_simple/Dockerfile
    runtime: nvidia
    entrypoint: ["/bin/bash", "-c", "ls ."]
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    volumes:
      - ./scripts:/app/llm_benchmarks/scripts
      - ./logs/:/var/log
      - /rocket/cpp:/models
    environment:
      - CUDA_VISIBLE_DEVICES=1

{
    "openai": [
        "gpt-4",
        "gpt-4-turbo-preview",
        "gpt-4-vision-preview",
        "gpt-4-0613",
        "gpt-4-1106-preview",
        "gpt-4-0125-preview",
        "gpt-4-turbo-2024-04-09",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-16k",
        "gpt-3.5-turbo-instruct",
        "gpt-3.5-turbo-0613",
        "gpt-3.5-turbo-16k-0613",
        "gpt-3.5-turbo-1106",
        "gpt-3.5-turbo-0125"
    ],
    "anthropic": [
        "claude-instant-1.2",
        "claude-2.1",
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307"
    ],
    "bedrock": [
        "anthropic.claude-instant-v1",
        "anthropic.claude-v2:1",
        "anthropic.claude-3-sonnet-20240229-v1:0",
        "anthropic.claude-3-haiku-20240307-v1:0",
        "amazon.titan-tg1-large",
        "amazon.titan-text-lite-v1",
        "amazon.titan-text-express-v1",
        "meta.llama2-70b-chat-v1",
        "meta.llama2-13b-chat-v1",
        "mistral.mistral-7b-instruct-v0:2",
        "mistral.mixtral-8x7b-instruct-v0:1"
    ],
    "vertex": [
        "text-bison@002",
        "gemini-pro",
        "gemini-1.0-pro",
        "gemini-1.5-pro-preview-0409",
        "claude-3-haiku@20240307",
        "claude-3-sonnet@20240229"
    ],
    "anyscale": [
        "meta-llama/Llama-2-7b-chat-hf",
        "meta-llama/Llama-2-13b-chat-hf",
        "meta-llama/Llama-2-70b-chat-hf",
        "mistralai/Mistral-7B-Instruct-v0.1",
        "mistralai/Mixtral-8x7B-Instruct-v0.1"
    ],
    "together": [
        "meta-llama/Llama-2-7b-hf",
        "meta-llama/Llama-2-13b-hf",
        "meta-llama/Llama-2-70b-hf",
        "meta-llama/Meta-Llama-3-8B",
        "meta-llama/Meta-Llama-3-70B",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "mistralai/Mixtral-8x22B",
        "google/gemma-2b-it",
        "google/gemma-7b-it",
        "microsoft/phi-2",
        "Qwen/Qwen1.5-4B-Chat",
        "Qwen/Qwen1.5-7B-Chat",
        "Qwen/Qwen1.5-14B-Chat",
        "Qwen/Qwen1.5-72B-Chat",
        "zero-one-ai/Yi-34B-Chat",
        "codellama/CodeLlama-34b-Instruct-hf",
        "databricks/dbrx-instruct"
    ],
    "openrouter": [
        "meta-llama/llama-2-13b-chat",
        "meta-llama/llama-2-70b-chat",
        "meta-llama/codellama-34b-instruct",
        "mistralai/mistral-7b-instruct",
        "mistralai/mixtral-8x7b-instruct",
        "01-ai/yi-34b-chat"
    ],
    "azure": [
        "llama-2-7b-chat",
        "llama-2-13b-chat",
        "llama-2-70b-chat",
        "mistral-large",
        "cohere-cmd-r-plus"
    ],
    "runpod": [
        "llama2-7b-chat",
        "llama2-13b-chat"
    ],
    "fireworks": [
        "accounts/fireworks/models/llama-v2-7b-chat",
        "accounts/fireworks/models/llama-v2-13b",
        "accounts/fireworks/models/llama-v2-13b-chat",
        "accounts/fireworks/models/llama-v2-34b-code",
        "accounts/fireworks/models/llama-v2-70b",
        "accounts/fireworks/models/llama-v2-70b-chat",
        "accounts/fireworks/models/mistral-7b",
        "accounts/fireworks/models/mixtral-8x7b",
        "accounts/fireworks/models/mixtral-8x7b-instruct",
        "accounts/fireworks/models/dbrx-instruct",
        "accounts/fireworks/models/gemma-7b-it",
        "accounts/fireworks/models/qwen-14b-chat",
        "accounts/fireworks/models/qwen-72b-chat"
    ],
    "deepinfra": [
        "meta-llama/Llama-2-70b-chat-hf",
        "meta-llama/Llama-2-7b-chat-hf",
        "codellama/CodeLlama-34b-Instruct-hf"
    ],
    "groq": [
        "llama2-70b-4096",
        "mixtral-8x7b-32768",
        "gemma-7b-it"
    ],
    "databricks": [
        "databricks-dbrx-instruct"
    ]
}

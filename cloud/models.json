{
    "openai": [
        "gpt-4",
        "gpt-4-turbo",
        "gpt-4o",
        "gpt-4o-2024-05-13",
        "gpt-4o-2024-08-06",
        "gpt-4o-2024-11-20",
        "gpt-4o-mini",
        "gpt-4o-mini-2024-07-18",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-instruct"
    ],
    "anthropic": [
        "claude-2.1",
        "claude-3-haiku-20240307",
        "claude-3-5-haiku-20241022",
        "claude-3-sonnet-20240229",
        "claude-3-5-sonnet-20240620",
        "claude-3-opus-20240229"
    ],
    "bedrock": [
        "anthropic.claude-3-haiku-20240307-v1:0",
        "us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "anthropic.claude-3-sonnet-20240229-v1:0",
        "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
        "us.anthropic.claude-3-opus-20240229-v1:0",
        "amazon.titan-text-lite-v1",
        "meta.llama3-8b-instruct-v1:0",
        "meta.llama3-70b-instruct-v1:0",
        "meta.llama3-1-8b-instruct-v1:0",
        "meta.llama3-1-70b-instruct-v1:0", // works (sometimes)
        "meta.llama3-1-405b-instruct-v1:0",
        "us.meta.llama3-2-1b-instruct-v1:0",
        "us.meta.llama3-2-3b-instruct-v1:0",
        "us.meta.llama3-2-11b-instruct-v1:0",
        "us.meta.llama3-2-90b-instruct-v1:0",
        "mistral.mistral-7b-instruct-v0:2",
        "mistral.mixtral-8x7b-instruct-v0:1",
        "mistral.mistral-small-2402-v1:0",
        "mistral.mistral-large-2402-v1:0",
        "cohere.command-r-v1:0",
        "cohere.command-r-plus-v1:0",
        "amazon.nova-pro-v1:0",
        "amazon.nova-lite-v1:0",
        "amazon.nova-micro-v1:0"
    ],
    "vertex": [
        "gemini-1.0-pro",
        "gemini-1.5-pro-002",
        "gemini-1.5-flash-002",
        "claude-3-haiku@20240307",
        "claude-3-5-haiku@20241022",
        "claude-3-sonnet@20240229",
        "claude-3-5-sonnet@20240620",
        "claude-3-opus@20240229",
        "meta/llama-3.2-90b-vision-instruct-maas"
    ],
    // "anyscale": [ # serverless has been deprecated
    //     "meta-llama/Llama-2-7b-chat-hf",
    //     "meta-llama/Llama-2-13b-chat-hf",
    //     "meta-llama/Llama-2-70b-chat-hf",
    //     "mistralai/Mistral-7B-Instruct-v0.1",
    //     "mistralai/Mixtral-8x7B-Instruct-v0.1",
    //     "mistralai/Mixtral-8x22B-Instruct-v0.1",
    //     "google/gemma-7b-it",
    //     "meta-llama/Meta-Llama-3-8B-Instruct",
    //     "meta-llama/Meta-Llama-3-70B-Instruct"
    // ],
    "together": [
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "meta-llama/Llama-Vision-Free", // 1b
        "meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
        "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "codellama/CodeLlama-34b-Instruct-hf",
        "qwen/Qwen2.5-7B-Instruct-Turbo",
        "qwen/Qwen2.5-72B-Instruct-Turbo",
        "google/gemma-2-9b-it",
        "google/gemma-2-27b-it",
        "mistralai/Mistral-7B-Instruct-v0.3",
        "deepseek-ai/deepseek-llm-67b-chat"
    ],
    "azure": [
        "llama-2-7b-chat",
        "llama-2-13b-chat",
        "llama-2-70b-chat",
        "mistral-large",
        "cohere-cmd-r-plus"
    ],
    "fireworks": [
        "accounts/fireworks/models/llama-v3-8b-instruct",
        "accounts/fireworks/models/llama-v3-8b-instruct-hf",
        "accounts/fireworks/models/llama-v3-70b-instruct",
        "accounts/fireworks/models/llama-v3-70b-instruct-hf",
        "accounts/fireworks/models/llama-v3p1-8b-instruct",
        "accounts/fireworks/models/llama-v3p1-70b-instruct",
        "accounts/fireworks/models/llama-v3p1-405b-instruct",
        "accounts/fireworks/models/llama-v3p2-1b-instruct",
        "accounts/fireworks/models/llama-v3p2-3b-instruct",
        "accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
        "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
        "accounts/fireworks/models/mixtral-8x7b-instruct",
        "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
        "accounts/fireworks/models/mixtral-8x22b-instruct",
        "accounts/fireworks/models/qwen2p5-72b-instruct",
        "accounts/fireworks/models/qwen2p5-coder-32b-instruct",
        "accounts/fireworks/models/starcoder-7b",
        "accounts/fireworks/models/starcoder-16b",
        "accounts/fireworks/models/gemma2-9b-it",
        "accounts/yi-01-ai/models/yi-large"
    ],
    "deepinfra": [
        "meta-llama/Llama-2-70b-chat-hf",
        "meta-llama/Llama-2-7b-chat-hf",
        "codellama/CodeLlama-34b-Instruct-hf",
        "meta-llama/Meta-Llama-3-8B-Instruct",
        "meta-llama/Meta-Llama-3-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-405B-Instruct",
        "meta-llama/Llama-3.2-1B-Instruct",
        "meta-llama/Llama-3.2-3B-Instruct",
        "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "meta-llama/Llama-3.2-90B-Vision-Instruct",
        "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "databricks/dbrx-instruct",
        "bigcode/starcoder2-15b",
        "Qwen/Qwen2.5-72B-Instruct"
    ],
    "groq": [
        "llama3-8b-8192",
        "llama3-70b-8192",
        "llama-3.1-8b-instant",
        "llama-3.1-70b-versatile",
        // "llama-3.1-405b-reasoning", // not available
        "llama-3.2-1b-preview",
        "llama-3.2-3b-preview",
        "llama-3.2-11b-text-preview",
        "llama-3.2-90b-text-preview",
        "mixtral-8x7b-32768",
        "gemma-7b-it",
        "gemma2-9b-it"
    ]
}
